{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrsaDfdVHzxt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# YOLOv5 Ultralytics\n",
    "\n",
    "Source:\n",
    "https://github.com/ultralytics/yolov5\n",
    "\n",
    "Tutorial:\n",
    "https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNveqeA1KXGy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 1: Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GX-x9g_D8UXF",
    "outputId": "7ee828db-084b-43c3-f235-287de32f8cb4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT = \"~/code/school/captcha-solver\" #@param {type:\"string\"}\n",
    "\n",
    "import os.path\n",
    "\n",
    "# Go to root of project.\n",
    "%cd {PROJECT_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTvDNSILZoN9",
    "outputId": "2dd2dee1-95ef-44a8-9270-4e55369b9356",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exist\n",
      "/Users/mve/code/school/captcha-solver/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Setup complete. Using torch 1.11.0 (CPU)\n"
     ]
    }
   ],
   "source": [
    "# Only clone repo if not already present\n",
    "if os.path.isdir(\"yolov5\"):\n",
    "  print (\"File exist\")\n",
    "else:\n",
    "  !git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt # install dependencies\n",
    "%pip install -q roboflow\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP6USLgz2f0r",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 2: Assemble Our Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2wGvjd4Z_92",
    "outputId": "cbd6ed8e-91ed-494c-96da-f129c4cba542",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2jjT5uIHo6l5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up environment\n",
    "os.environ[\"DATASET_DIRECTORY\"] = PROJECT_ROOT + \"/datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYAKYDMg96Oq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Change the following code to switch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwJcaoPGF4VI",
    "outputId": "cce5cb32-71e5-40ec-df4b-8ac75d637aa7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in ~/code/school/captcha-solver/datasets/CAPTCHA-images-33 to yolov5pytorch: 50% [24567808 / 48264801] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in ~/code/school/captcha-solver/datasets/CAPTCHA-images-33 to yolov5pytorch: 100% [48264801 / 48264801] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to ~/code/school/captcha-solver/datasets/CAPTCHA-images-33 in yolov5pytorch:: 100%|██████████| 2018/2018 [00:00<00:00, 7467.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# after following the link above, recieve python code with these fields filled in\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"lpAPGdHq3w2H0vl0cBAu\")\n",
    "project = rf.workspace(\"captcha-solver\").project(\"captcha-images\")\n",
    "dataset = project.version(33).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7yAi9hd-T4B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 3: Train Our Custom YOLOv5 model\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
    "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
    "- **cache:** cache images for faster training\n",
    "\n",
    "You can switch weights to any of these pretrained checkpoints:\n",
    "https://github.com/ultralytics/yolov5#pretrained-checkpoints\n",
    "\n",
    "# Model info\n",
    "Tested with 120 epochs, 786 images stretched to 640x640 on a Tesla K80.\n",
    "- yolov5n6: will take an estimated 1.3 hours\n",
    "- yolov5s6: will take an estimated 2 hours\n",
    "- yolov5m6: will take an estimated 5 hours\n",
    "- yolov5l6: will take an estimated 9 hours\n",
    "- yolov5x6: Not enough GPU RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IdaupgE430YP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = 'yolov5n6.pt' #@param [\"yolov5n6.pt\", \"yolov5s6.pt\", \"yolov5m6.pt\", \"yolov5l6.pt\", \"yolov5x6.pt\"] {allow-input: true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8OwBWU2yk7Z",
    "outputId": "a50662e9-a3ef-44a6-f797-58ee539cf2e8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (0.12.14)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (8.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: PyYAML in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: setproctitle in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (1.5.10)\n",
      "Requirement already satisfied: pathtools in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/mve/miniforge3/envs/yolov5-ultralytics/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Install wandb for tracking and visualizing YOLOv5 runs.\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "LOZr_hp2V_b1",
    "outputId": "bd06a0f5-3b31-434a-e113-b23e8c21f970",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /Users/mve/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sltbyUC12zTp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# --resume wandb-artifact://han-captcha/YOLOv5/1182ptzf\n",
    "# {model}\n",
    "# /content/best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaFNnxLJbq4J",
    "outputId": "6d839d5e-823a-4542-f322-673bcb41d47d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5n6.pt, cfg=, data=/Users/mve/code/school/captcha-solver/yolov5/~/code/school/captcha-solver/datasets/CAPTCHA-images-33/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=8, imgsz=800, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v6.1-135-g7926afc torch 1.11.0 CPU\n",
      "\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.14\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/Users/mve/code/school/captcha-solver/yolov5/wandb/run-20220419_201835-3fepctrv\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mdazzling-frost-36\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/han-captcha/YOLOv5\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/han-captcha/YOLOv5/runs/3fepctrv\u001B[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5n6.pt to yolov5n6.pt...\n",
      "100%|██████████████████████████████████████| 6.86M/6.86M [00:00<00:00, 31.3MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=26\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
      "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
      "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
      "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
      "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  7                -1  1    221568  models.common.Conv                      [128, 192, 3, 2]              \n",
      "  8                -1  1    167040  models.common.C3                        [192, 192, 1]                 \n",
      "  9                -1  1    442880  models.common.Conv                      [192, 256, 3, 2]              \n",
      " 10                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
      " 11                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
      " 12                -1  1     49536  models.common.Conv                      [256, 192, 1, 1]              \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  1    203904  models.common.C3                        [384, 192, 1, False]          \n",
      " 16                -1  1     24832  models.common.Conv                      [192, 128, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 20                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 24                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
      " 27                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  1    179328  models.common.C3                        [256, 192, 1, False]          \n",
      " 30                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  1    329216  models.common.C3                        [384, 256, 1, False]          \n",
      " 33  [23, 26, 29, 32]  1     59892  models.yolo.Detect                      [26, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [64, 128, 192, 256]]\n",
      "Model summary: 355 layers, 3142612 parameters, 3142612 gradients\n",
      "\n",
      "Transferred 451/459 items from yolov5n6.pt\n",
      "WARNING: --img-size 800 must be multiple of max stride 64, updating to 832\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD with parameter groups 75 weight (no decay), 79 weight, 79 bias\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/Users/mve/code/school/captcha-solver/yolov5/~/code/school/capt\u001B[0m\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/Users/mve/code/school/captcha-solver/yolov5/~/code/school/capt\u001B[0m\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/Users/mve/code/school/captcha-solver/yolov5/~/code/school/capt\u001B[0m\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /Users/mve/code/school/captcha-solver/yolov5/~/code/school/captcha-solver/datasets/CAPTCHA-images-33/train/labels.cache\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mCaching images (0.5GB ram): 100%|██████████| 897/897 [00:00<00:00, 3392.2\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/Users/mve/code/school/captcha-solver/yolov5/~/code/school/captch\u001B[0m\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/Users/mve/code/school/captcha-solver/yolov5/~/code/school/captch\u001B[0m\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/Users/mve/code/school/captcha-solver/yolov5/~/code/school/captch\u001B[0m\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /Users/mve/code/school/captcha-solver/yolov5/~/code/school/captcha-solver/datasets/CAPTCHA-images-33/valid/labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mCaching images (0.0GB ram): 100%|██████████| 81/81 [00:00<00:00, 2319.18it/\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhan-captcha\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "Plotting labels to runs/train/exp/labels.jpg... \n",
      "\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m6.82 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 832 train, 832 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns/train/exp\u001B[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/4        0G    0.0781   0.07766   0.07167        14       832: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 0.580s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 0.580s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 0.580s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 0.580s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 0.580s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         81        486     0.0156      0.339     0.0197    0.00396\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/4        0G   0.05843    0.0631   0.07433        80       832:   4%|▍  \u001B[34m\u001B[1mwandb\u001B[0m: Network error (SSLError), entering retry loop.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error (SSLError), entering retry loop.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error (SSLError), entering retry loop.\n",
      "       1/4        0G   0.05632   0.06388   0.07227       125       832:   5%|▌  \u001B[34m\u001B[1mwandb\u001B[0m: Network error (SSLError), entering retry loop.\n",
      "       1/4        0G   0.05927   0.05328   0.06318        20       832: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         81        486     0.0548      0.133     0.0162    0.00428\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/4        0G   0.05426   0.04827    0.0579        72       832:   8%|▊  \u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:15.812476, resuming normal operation.\n",
      "       2/4        0G   0.05327    0.0489   0.05938        20       832: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         81        486      0.293      0.278      0.086     0.0239\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/4        0G   0.04285   0.05292   0.05976        88       832:   6%|▌  \u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:12.321265, resuming normal operation.\n",
      "       3/4        0G   0.04298   0.04517   0.05961       102       832:  58%|███"
     ]
    }
   ],
   "source": [
    "!python train.py --img 800 --batch 8 --epochs 5 --data {dataset.location}/data.yaml --weights {model} --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcIRLQOlA14A",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate Custom YOLOv5 Detector Performance\n",
    "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
    "\n",
    "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtmS7_TXFsT3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#Run Inference  With Trained Weights\n",
    "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWjjiBcic3Vz",
    "outputId": "3f50260f-9a64-42cc-be36-b2ea14898a6a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use newly run weights.\n",
    "!python detect.py --weights runs/train/exp/weights/best.pt --img 800 --conf 0.1 --source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b1qbS_i8Prj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use existing weights.\n",
    "# !python detect.py --weights /content/v11-yolov5s6.pt --img 800 --conf 0.1 --source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZbUn4_b9GCKO",
    "outputId": "0385f446-56aa-4a70-cc3e-f8908121b01a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# display inference on ALL test images\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob(PROJECT_ROOT + '/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8dHcni6CJYt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
    "\n",
    "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
    "\n",
    "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
    "\n",
    "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "7iiObB2WCMh6",
    "outputId": "d1f0bb13-9f96-42f3-f0f9-d78fb0cfabec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Export your model's weights for future use\n",
    "from google.colab import files\n",
    "files.download('./runs/train/exp/weights/best.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YOLOv5 Ultralytics",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}